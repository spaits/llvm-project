; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=arm64_32-apple-ios7.0 %s -filetype=obj -o - -disable-post-ra -frame-pointer=non-leaf | \
; RUN:     llvm-objdump --private-headers - | \
; RUN:     FileCheck %s --check-prefix=CHECK-MACHO
; RUN: llc -mtriple=arm64_32-apple-ios7.0 %s -o - -aarch64-enable-atomic-cfg-tidy=0 -disable-post-ra -frame-pointer=non-leaf | FileCheck %s --check-prefix=CHECK --check-prefix=CHECK-OPT
; RUN: llc -mtriple=arm64_32-apple-ios7.0 %s -o - -fast-isel -aarch64-enable-atomic-cfg-tidy=0 -disable-post-ra -frame-pointer=non-leaf | FileCheck %s --check-prefix=CHECK --check-prefix=CHECK-FAST

; CHECK-MACHO: Mach header
; CHECK-MACHO: MH_MAGIC ARM64_32 V8

@var64 = global i64 zeroinitializer, align 8
@var32 = global i32 zeroinitializer, align 4

@var_got = external global i8

define ptr @test_global_addr() {
; CHECK-OPT-LABEL: test_global_addr:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:  Lloh0:
; CHECK-OPT-NEXT:    adrp x0, _var32@PAGE
; CHECK-OPT-NEXT:  Lloh1:
; CHECK-OPT-NEXT:    add x0, x0, _var32@PAGEOFF
; CHECK-OPT-NEXT:    ret
; CHECK-OPT-NEXT:    .loh AdrpAdd Lloh0, Lloh1
;
; CHECK-FAST-LABEL: test_global_addr:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:  Lloh0:
; CHECK-FAST-NEXT:    adrp x8, _var32@PAGE
; CHECK-FAST-NEXT:  Lloh1:
; CHECK-FAST-NEXT:    add x8, x8, _var32@PAGEOFF
; CHECK-FAST-NEXT:    and x0, x8, #0xffffffff
; CHECK-FAST-NEXT:    ret
; CHECK-FAST-NEXT:    .loh AdrpAdd Lloh0, Lloh1
  ret ptr @var32
}

; ADRP is necessarily 64-bit. The important point to check is that, however that
; gets truncated to 32-bits, it's free. No need to zero out higher bits of that
; register.
define i64 @test_global_addr_extension() {
; CHECK-OPT-LABEL: test_global_addr_extension:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:  Lloh2:
; CHECK-OPT-NEXT:    adrp x0, _var32@PAGE
; CHECK-OPT-NEXT:  Lloh3:
; CHECK-OPT-NEXT:    add x0, x0, _var32@PAGEOFF
; CHECK-OPT-NEXT:    ret
; CHECK-OPT-NEXT:    .loh AdrpAdd Lloh2, Lloh3
;
; CHECK-FAST-LABEL: test_global_addr_extension:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:  Lloh2:
; CHECK-FAST-NEXT:    adrp x8, _var32@PAGE
; CHECK-FAST-NEXT:  Lloh3:
; CHECK-FAST-NEXT:    add x0, x8, _var32@PAGEOFF
; CHECK-FAST-NEXT:    ret
; CHECK-FAST-NEXT:    .loh AdrpAdd Lloh2, Lloh3

  ret i64 ptrtoint(ptr @var32 to i64)
}

define i32 @test_global_value() {
; CHECK-LABEL: test_global_value:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh4:
; CHECK-NEXT:    adrp x8, _var32@PAGE
; CHECK-NEXT:  Lloh5:
; CHECK-NEXT:    ldr w0, [x8, _var32@PAGEOFF]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpLdr Lloh4, Lloh5
  %val = load i32, ptr @var32, align 4
  ret i32 %val
}

; Because the addition may wrap, it is not safe to use "ldr w0, [xN, #32]" here.
define i32 @test_unsafe_indexed_add() {
; CHECK-LABEL: test_unsafe_indexed_add:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh6:
; CHECK-NEXT:    adrp x8, _var32@PAGE
; CHECK-NEXT:  Lloh7:
; CHECK-NEXT:    add x8, x8, _var32@PAGEOFF
; CHECK-NEXT:    add w8, w8, #32
; CHECK-NEXT:    ldr w0, [x8]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpAdd Lloh6, Lloh7
  %addr_int = ptrtoint ptr @var32 to i32
  %addr_plus_32 = add i32 %addr_int, 32
  %addr = inttoptr i32 %addr_plus_32 to ptr
  %val = load i32, ptr %addr, align 4
  ret i32 %val
}

; Since we've promised there is no unsigned overflow, @var32 must be at least
; 32-bytes below 2^32, and we can use the load this time.
define i32 @test_safe_indexed_add() {
; CHECK-LABEL: test_safe_indexed_add:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh8:
; CHECK-NEXT:    adrp x8, _var32@PAGE
; CHECK-NEXT:  Lloh9:
; CHECK-NEXT:    add x8, x8, _var32@PAGEOFF
; CHECK-NEXT:    add w8, w8, #32
; CHECK-NEXT:    ldr w0, [x8]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpAdd Lloh8, Lloh9
  %addr_int = ptrtoint ptr @var32 to i64
  %addr_plus_32 = add nuw i64 %addr_int, 32
  %addr = inttoptr i64 %addr_plus_32 to ptr
  %val = load i32, ptr %addr, align 4
  ret i32 %val
}

define i32 @test_safe_indexed_or(i32 %in) {
; CHECK-LABEL: test_safe_indexed_or:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    and w8, w0, #0xfffffff0
; CHECK-NEXT:    orr w8, w8, #0x4
; CHECK-NEXT:    ldr w0, [x8]
; CHECK-NEXT:    ret
  %addr_int = and i32 %in, -16
  %addr_plus_4 = or i32 %addr_int, 4
  %addr = inttoptr i32 %addr_plus_4 to ptr
  %val = load i32, ptr %addr, align 4
  ret i32 %val
}


; Promising nsw is not sufficient because the addressing mode basically
; calculates "zext(base) + zext(offset)" and nsw only guarantees
; "sext(base) + sext(offset) == base + offset".
define i32 @test_unsafe_nsw_indexed_add() {
; CHECK-LABEL: test_unsafe_nsw_indexed_add:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh10:
; CHECK-NEXT:    adrp x8, _var32@PAGE
; CHECK-NEXT:  Lloh11:
; CHECK-NEXT:    add x8, x8, _var32@PAGEOFF
; CHECK-NEXT:    add w8, w8, #32
; CHECK-NEXT:    ldr w0, [x8]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpAdd Lloh10, Lloh11
  %addr_int = ptrtoint ptr @var32 to i32
  %addr_plus_32 = add nsw i32 %addr_int, 32
  %addr = inttoptr i32 %addr_plus_32 to ptr
  %val = load i32, ptr %addr, align 4
  ret i32 %val
}

; Because the addition may wrap, it is not safe to use "ldr w0, [xN, #32]" here.
define i32 @test_unsafe_unscaled_add() {
; CHECK-LABEL: test_unsafe_unscaled_add:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh12:
; CHECK-NEXT:    adrp x8, _var32@PAGE
; CHECK-NEXT:  Lloh13:
; CHECK-NEXT:    add x8, x8, _var32@PAGEOFF
; CHECK-NEXT:    add w8, w8, #3
; CHECK-NEXT:    ldr w0, [x8]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpAdd Lloh12, Lloh13
  %addr_int = ptrtoint ptr @var32 to i32
  %addr_plus_3 = add i32 %addr_int, 3
  %addr = inttoptr i32 %addr_plus_3 to ptr
  %val = load i32, ptr %addr, align 1
  ret i32 %val
}

; Since we've promised there is no unsigned overflow, @var32 must be at least
; 32-bytes below 2^32, and we can use the load this time.
define i32 @test_safe_unscaled_add() {
; CHECK-LABEL: test_safe_unscaled_add:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh14:
; CHECK-NEXT:    adrp x8, _var32@PAGE
; CHECK-NEXT:  Lloh15:
; CHECK-NEXT:    add x8, x8, _var32@PAGEOFF
; CHECK-NEXT:    add w8, w8, #3
; CHECK-NEXT:    ldr w0, [x8]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpAdd Lloh14, Lloh15
  %addr_int = ptrtoint ptr @var32 to i32
  %addr_plus_3 = add nuw i32 %addr_int, 3
  %addr = inttoptr i32 %addr_plus_3 to ptr
  %val = load i32, ptr %addr, align 1
  ret i32 %val
}

; Promising nsw is not sufficient because the addressing mode basically
; calculates "zext(base) + zext(offset)" and nsw only guarantees
; "sext(base) + sext(offset) == base + offset".
define i32 @test_unsafe_nsw_unscaled_add() {
; CHECK-LABEL: test_unsafe_nsw_unscaled_add:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh16:
; CHECK-NEXT:    adrp x8, _var32@PAGE
; CHECK-NEXT:  Lloh17:
; CHECK-NEXT:    add x8, x8, _var32@PAGEOFF
; CHECK-NEXT:    add w8, w8, #3
; CHECK-NEXT:    ldr w0, [x8]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpAdd Lloh16, Lloh17
  %addr_int = ptrtoint ptr @var32 to i32
  %addr_plus_3 = add nsw i32 %addr_int, 3
  %addr = inttoptr i32 %addr_plus_3 to ptr
  %val = load i32, ptr %addr, align 1
  ret i32 %val
}

; Because the addition may wrap, it is not safe to use "ldur w0, [xN, #-3]"
; here.
define i32 @test_unsafe_negative_unscaled_add() {
; CHECK-LABEL: test_unsafe_negative_unscaled_add:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh18:
; CHECK-NEXT:    adrp x8, _var32@PAGE
; CHECK-NEXT:  Lloh19:
; CHECK-NEXT:    add x8, x8, _var32@PAGEOFF
; CHECK-NEXT:    sub w8, w8, #3
; CHECK-NEXT:    ldr w0, [x8]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpAdd Lloh18, Lloh19
  %addr_int = ptrtoint ptr @var32 to i32
  %addr_minus_3 = add i32 %addr_int, -3
  %addr = inttoptr i32 %addr_minus_3 to ptr
  %val = load i32, ptr %addr, align 1
  ret i32 %val
}

define ptr @test_got_addr() {
; CHECK-OPT-LABEL: test_got_addr:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:  Lloh20:
; CHECK-OPT-NEXT:    adrp x0, _var_got@GOTPAGE
; CHECK-OPT-NEXT:  Lloh21:
; CHECK-OPT-NEXT:    ldr w0, [x0, _var_got@GOTPAGEOFF]
; CHECK-OPT-NEXT:    ret
; CHECK-OPT-NEXT:    .loh AdrpLdrGot Lloh20, Lloh21
;
; CHECK-FAST-LABEL: test_got_addr:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:  Lloh20:
; CHECK-FAST-NEXT:    adrp x8, _var_got@GOTPAGE
; CHECK-FAST-NEXT:  Lloh21:
; CHECK-FAST-NEXT:    ldr w8, [x8, _var_got@GOTPAGEOFF]
; CHECK-FAST-NEXT:    and x0, x8, #0xffffffff
; CHECK-FAST-NEXT:    ret
; CHECK-FAST-NEXT:    .loh AdrpLdrGot Lloh20, Lloh21
  ret ptr @var_got
}

define float @test_va_arg_f32(ptr %list) {
; CHECK-LABEL: test_va_arg_f32:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    ldr w8, [x0]
; CHECK-NEXT:    add w9, w8, #8
; CHECK-NEXT:    str w9, [x0]
; CHECK-NEXT:    ldr d0, [x8]
; CHECK-NEXT:    fcvt s0, d0
; CHECK-NEXT:    ret


  ; Floating point arguments get promoted to double as per C99.
  %res = va_arg ptr %list, float
  ret float %res
}

; Interesting point is that the slot is 4 bytes.
define i8 @test_va_arg_i8(ptr %list) {
; CHECK-LABEL: test_va_arg_i8:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    ldr w8, [x0]
; CHECK-NEXT:    add w9, w8, #4
; CHECK-NEXT:    str w9, [x0]
; CHECK-NEXT:    ldr w0, [x8]
; CHECK-NEXT:    ret


  ; i8 gets promoted to int (again, as per C99).

  %res = va_arg ptr %list, i8
  ret i8 %res
}

; Interesting point is that the slot needs aligning (again, min size is 4
; bytes).
define i64 @test_va_arg_i64(ptr %list) {
; CHECK-LABEL: test_va_arg_i64:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    ldr w8, [x0]
; CHECK-NEXT:    add x8, x8, #7
; CHECK-NEXT:    and x8, x8, #0x1fffffff8
; CHECK-NEXT:    add w9, w8, #8
; CHECK-NEXT:    str w9, [x0]
; CHECK-NEXT:    ldr x0, [x8]
; CHECK-NEXT:    ret

  ; Update the list for the next user (minimum slot size is 4, but the actual
  ; argument is 8 which had better be reflected!)


  %res = va_arg ptr %list, i64
  ret i64 %res
}

declare void @bar(...)
define void @test_va_call(i8 %l, i8 %r, float %in, ptr %ptr) {
; CHECK-OPT-LABEL: test_va_call:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:    sub sp, sp, #64
; CHECK-OPT-NEXT:    stp x29, x30, [sp, #48] ; 16-byte Folded Spill
; CHECK-OPT-NEXT:    add x29, sp, #48
; CHECK-OPT-NEXT:    .cfi_def_cfa w29, 16
; CHECK-OPT-NEXT:    .cfi_offset w30, -8
; CHECK-OPT-NEXT:    .cfi_offset w29, -16
; CHECK-OPT-NEXT:    add w8, w0, w1
; CHECK-OPT-NEXT:    str w2, [sp, #32]
; CHECK-OPT-NEXT:    str xzr, [sp, #24]
; CHECK-OPT-NEXT:    str s0, [sp, #16]
; CHECK-OPT-NEXT:    str xzr, [sp, #8]
; CHECK-OPT-NEXT:    str w8, [sp]
; CHECK-OPT-NEXT:    bl _bar
; CHECK-OPT-NEXT:    ldp x29, x30, [sp, #48] ; 16-byte Folded Reload
; CHECK-OPT-NEXT:    add sp, sp, #64
; CHECK-OPT-NEXT:    ret
;
; CHECK-FAST-LABEL: test_va_call:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:    sub sp, sp, #64
; CHECK-FAST-NEXT:    stp x29, x30, [sp, #48] ; 16-byte Folded Spill
; CHECK-FAST-NEXT:    add x29, sp, #48
; CHECK-FAST-NEXT:    .cfi_def_cfa w29, 16
; CHECK-FAST-NEXT:    .cfi_offset w30, -8
; CHECK-FAST-NEXT:    .cfi_offset w29, -16
; CHECK-FAST-NEXT:    sxtb w8, w0
; CHECK-FAST-NEXT:    add w8, w8, w1, sxtb
; CHECK-FAST-NEXT:    str w2, [sp, #32]
; CHECK-FAST-NEXT:    str xzr, [sp, #24]
; CHECK-FAST-NEXT:    str s0, [sp, #16]
; CHECK-FAST-NEXT:    str xzr, [sp, #8]
; CHECK-FAST-NEXT:    str w8, [sp]
; CHECK-FAST-NEXT:    bl _bar
; CHECK-FAST-NEXT:    ldp x29, x30, [sp, #48] ; 16-byte Folded Reload
; CHECK-FAST-NEXT:    add sp, sp, #64
; CHECK-FAST-NEXT:    ret


  ; Add them to ensure real promotion occurs.
  %sum = add i8 %l, %r
  call void(...) @bar(i8 %sum, i64 0, float %in, double 0.0, ptr %ptr)
  ret void
}

declare ptr @llvm.frameaddress(i32)

define ptr @test_frameaddr() {
; CHECK-OPT-LABEL: test_frameaddr:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-OPT-NEXT:    mov x29, sp
; CHECK-OPT-NEXT:    .cfi_def_cfa w29, 16
; CHECK-OPT-NEXT:    .cfi_offset w30, -8
; CHECK-OPT-NEXT:    .cfi_offset w29, -16
; CHECK-OPT-NEXT:    ldr x0, [x29]
; CHECK-OPT-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-OPT-NEXT:    ret
;
; CHECK-FAST-LABEL: test_frameaddr:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-FAST-NEXT:    mov x29, sp
; CHECK-FAST-NEXT:    .cfi_def_cfa w29, 16
; CHECK-FAST-NEXT:    .cfi_offset w30, -8
; CHECK-FAST-NEXT:    .cfi_offset w29, -16
; CHECK-FAST-NEXT:    ldr x8, [x29]
; CHECK-FAST-NEXT:    and x0, x8, #0xffffffff
; CHECK-FAST-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-FAST-NEXT:    ret
  %val = call ptr @llvm.frameaddress(i32 1)
  ret ptr %val
}

declare ptr @llvm.returnaddress(i32)

define ptr @test_toplevel_returnaddr() {
; CHECK-OPT-LABEL: test_toplevel_returnaddr:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-OPT-NEXT:    .cfi_def_cfa_offset 16
; CHECK-OPT-NEXT:    .cfi_offset w30, -8
; CHECK-OPT-NEXT:    .cfi_offset w29, -16
; CHECK-OPT-NEXT:    hint #7
; CHECK-OPT-NEXT:    mov x0, x30
; CHECK-OPT-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-OPT-NEXT:    ret
;
; CHECK-FAST-LABEL: test_toplevel_returnaddr:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-FAST-NEXT:    .cfi_def_cfa_offset 16
; CHECK-FAST-NEXT:    .cfi_offset w30, -8
; CHECK-FAST-NEXT:    .cfi_offset w29, -16
; CHECK-FAST-NEXT:    hint #7
; CHECK-FAST-NEXT:    and x0, x30, #0xffffffff
; CHECK-FAST-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-FAST-NEXT:    ret
  %val = call ptr @llvm.returnaddress(i32 0)
  ret ptr %val
}

define ptr @test_deep_returnaddr() {
; CHECK-OPT-LABEL: test_deep_returnaddr:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-OPT-NEXT:    mov x29, sp
; CHECK-OPT-NEXT:    .cfi_def_cfa w29, 16
; CHECK-OPT-NEXT:    .cfi_offset w30, -8
; CHECK-OPT-NEXT:    .cfi_offset w29, -16
; CHECK-OPT-NEXT:    ldr x8, [x29]
; CHECK-OPT-NEXT:    ldr x0, [x8, #8]
; CHECK-OPT-NEXT:    hint #7
; CHECK-OPT-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-OPT-NEXT:    ret
;
; CHECK-FAST-LABEL: test_deep_returnaddr:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-FAST-NEXT:    mov x29, sp
; CHECK-FAST-NEXT:    .cfi_def_cfa w29, 16
; CHECK-FAST-NEXT:    .cfi_offset w30, -8
; CHECK-FAST-NEXT:    .cfi_offset w29, -16
; CHECK-FAST-NEXT:    ldr x8, [x29]
; CHECK-FAST-NEXT:    ldr x30, [x8, #8]
; CHECK-FAST-NEXT:    hint #7
; CHECK-FAST-NEXT:    and x0, x30, #0xffffffff
; CHECK-FAST-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-FAST-NEXT:    ret
  %val = call ptr @llvm.returnaddress(i32 1)
  ret ptr %val
}

define void @test_indirect_call(ptr %func) {
; CHECK-LABEL: test_indirect_call:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-NEXT:    mov x29, sp
; CHECK-NEXT:    .cfi_def_cfa w29, 16
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    blr x0
; CHECK-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-NEXT:    ret
  call void() %func()
  ret void
}

; Safe to use the unextended address here
define void @test_indirect_safe_call(ptr %weird_funcs) {
; CHECK-LABEL: test_indirect_safe_call:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-NEXT:    mov x29, sp
; CHECK-NEXT:    .cfi_def_cfa w29, 16
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    add w8, w0, #4
; CHECK-NEXT:    blr x8
; CHECK-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-NEXT:    ret
  %addr = getelementptr i32, ptr %weird_funcs, i32 1
  call void() %addr()
  ret void
}

declare void @simple()
define void @test_simple_tail_call() {
; CHECK-LABEL: test_simple_tail_call:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    b _simple
  tail call void @simple()
  ret void
}

define void @test_indirect_tail_call(ptr %func) {
; CHECK-LABEL: test_indirect_tail_call:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    br x0
  tail call void() %func()
  ret void
}

; Safe to use the unextended address here
define void @test_indirect_safe_tail_call(ptr %weird_funcs) {
; CHECK-LABEL: test_indirect_safe_tail_call:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    add w0, w0, #4
; CHECK-NEXT:    br x0
  %addr = getelementptr i32, ptr %weird_funcs, i32 1
  tail call void() %addr()
  ret void
}

; For the "armv7k" slice, Clang will be emitting some small structs as [N x
; i32]. For ABI compatibility with arm64_32 these need to be passed in *X*
; registers (e.g. [2 x i32] would be packed into a single register).

define i32 @test_in_smallstruct_low([3 x i32] %in) {
; CHECK-LABEL: test_in_smallstruct_low:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    mov x0, x1
; CHECK-NEXT:    ; kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
  %val = extractvalue [3 x i32] %in, 2
  ret i32 %val
}

define i32 @test_in_smallstruct_high([3 x i32] %in) {
; CHECK-LABEL: test_in_smallstruct_high:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    lsr x0, x0, #32
; CHECK-NEXT:    ; kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
  %val = extractvalue [3 x i32] %in, 1
  ret i32 %val
}

; The 64-bit DarwinPCS ABI has the quirk that structs on the stack are always
; 64-bit aligned. This must not happen for arm64_32 since othwerwise va_arg will
; be incompatible with the armv7k ABI.
define i32 @test_in_smallstruct_stack([8 x i64], i32, [3 x i32] %in) {
; CHECK-LABEL: test_in_smallstruct_stack:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    ldr w0, [sp, #4]
; CHECK-NEXT:    ret
  %val = extractvalue [3 x i32] %in, 0
  ret i32 %val
}

define [2 x i32] @test_ret_smallstruct([3 x i32] %in) {
; CHECK-LABEL: test_ret_smallstruct:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    mov x0, #1 ; =0x1
; CHECK-NEXT:    movk x0, #2, lsl #32
; CHECK-NEXT:    ret

  ret [2 x i32] [i32 1, i32 2]
}

declare void @smallstruct_callee([4 x i32])
define void @test_call_smallstruct() {
; CHECK-LABEL: test_call_smallstruct:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-NEXT:    mov x29, sp
; CHECK-NEXT:    .cfi_def_cfa w29, 16
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    mov x0, #1 ; =0x1
; CHECK-NEXT:    movk x0, #2, lsl #32
; CHECK-NEXT:    mov x1, #3 ; =0x3
; CHECK-NEXT:    movk x1, #4, lsl #32
; CHECK-NEXT:    bl _smallstruct_callee
; CHECK-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-NEXT:    ret

  call void @smallstruct_callee([4 x i32] [i32 1, i32 2, i32 3, i32 4])
  ret void
}

declare void @smallstruct_callee_stack([8 x i64], i32, [2 x i32])
define void @test_call_smallstruct_stack() {
; CHECK-LABEL: test_call_smallstruct_stack:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    sub sp, sp, #32
; CHECK-NEXT:    stp x29, x30, [sp, #16] ; 16-byte Folded Spill
; CHECK-NEXT:    add x29, sp, #16
; CHECK-NEXT:    .cfi_def_cfa w29, 16
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    mov x8, #1 ; =0x1
; CHECK-NEXT:    movk x8, #2, lsl #32
; CHECK-NEXT:    stur x8, [sp, #4]
; CHECK-NEXT:    bl _smallstruct_callee_stack
; CHECK-NEXT:    ldp x29, x30, [sp, #16] ; 16-byte Folded Reload
; CHECK-NEXT:    add sp, sp, #32
; CHECK-NEXT:    ret

  call void @smallstruct_callee_stack([8 x i64] undef, i32 undef, [2 x i32] [i32 1, i32 2])
  ret void
}

declare [3 x i32] @returns_smallstruct()
define i32 @test_use_smallstruct_low() {
; CHECK-LABEL: test_use_smallstruct_low:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-NEXT:    mov x29, sp
; CHECK-NEXT:    .cfi_def_cfa w29, 16
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    bl _returns_smallstruct
; CHECK-NEXT:    mov x0, x1
; CHECK-NEXT:    ; kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-NEXT:    ret

  %struct = call [3 x i32] @returns_smallstruct()
  %val = extractvalue [3 x i32] %struct, 2
  ret i32 %val
}

define i32 @test_use_smallstruct_high() {
; CHECK-LABEL: test_use_smallstruct_high:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-NEXT:    mov x29, sp
; CHECK-NEXT:    .cfi_def_cfa w29, 16
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    bl _returns_smallstruct
; CHECK-NEXT:    lsr x0, x0, #32
; CHECK-NEXT:    ; kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-NEXT:    ret

  %struct = call [3 x i32] @returns_smallstruct()
  %val = extractvalue [3 x i32] %struct, 1
  ret i32 %val
}

; If a small struct can't be allocated to x0-x7, the remaining registers should
; be marked as unavailable and subsequent GPR arguments should also be on the
; stack. Obviously the struct itself should be passed entirely on the stack.
define i32 @test_smallstruct_padding([7 x i64], [4 x i32] %struct, i32 %in) {
; CHECK-OPT-LABEL: test_smallstruct_padding:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:    ldr w8, [sp, #16]
; CHECK-OPT-NEXT:    ldr w9, [sp]
; CHECK-OPT-NEXT:    add w0, w9, w8
; CHECK-OPT-NEXT:    ret
;
; CHECK-FAST-LABEL: test_smallstruct_padding:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:    ldr w8, [sp]
; CHECK-FAST-NEXT:    ldr w9, [sp, #16]
; CHECK-FAST-NEXT:    add w0, w8, w9
; CHECK-FAST-NEXT:    ret
  %lhs = extractvalue [4 x i32] %struct, 0
  %sum = add i32 %lhs, %in
  ret i32 %sum
}

declare void @take_small_smallstruct(i64, [1 x i32])
define void @test_small_smallstruct() {
; CHECK-LABEL: test_small_smallstruct:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-NEXT:    mov x29, sp
; CHECK-NEXT:    .cfi_def_cfa w29, 16
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    mov w0, #1 ; =0x1
; CHECK-NEXT:    mov w1, #2 ; =0x2
; CHECK-NEXT:    bl _take_small_smallstruct
; CHECK-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-NEXT:    ret
  call void @take_small_smallstruct(i64 1, [1 x i32] [i32 2])
  ret void
}

define void @test_bare_frameaddr(ptr %addr) {
; CHECK-LABEL: test_bare_frameaddr:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    sub sp, sp, #16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    add x8, sp, #15
; CHECK-NEXT:    str w8, [x0]
; CHECK-NEXT:    add sp, sp, #16
; CHECK-NEXT:    ret

  %ptr = alloca i8
  store ptr %ptr, ptr %addr, align 4
  ret void
}

define void @test_sret_use(ptr sret([8 x i64]) %out) {
; CHECK-LABEL: test_sret_use:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    str xzr, [x8]
; CHECK-NEXT:    ret
  store i64 0, ptr %out
  ret void
}

define i64 @test_sret_call() {
; CHECK-LABEL: test_sret_call:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    sub sp, sp, #80
; CHECK-NEXT:    stp x29, x30, [sp, #64] ; 16-byte Folded Spill
; CHECK-NEXT:    add x29, sp, #64
; CHECK-NEXT:    .cfi_def_cfa w29, 16
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    mov x8, sp
; CHECK-NEXT:    bl _test_sret_use
; CHECK-NEXT:    ldr x0, [sp]
; CHECK-NEXT:    ldp x29, x30, [sp, #64] ; 16-byte Folded Reload
; CHECK-NEXT:    add sp, sp, #80
; CHECK-NEXT:    ret
  %arr = alloca [8 x i64]
  call void @test_sret_use(ptr sret([8 x i64]) %arr)

  %val = load i64, ptr %arr
  ret i64 %val
}

define double @test_constpool() {
; CHECK-LABEL: test_constpool:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh22:
; CHECK-NEXT:    adrp x8, lCPI37_0@PAGE
; CHECK-NEXT:  Lloh23:
; CHECK-NEXT:    ldr d0, [x8, lCPI37_0@PAGEOFF]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpLdr Lloh22, Lloh23
  ret double 1.0e-6
}

define ptr @test_blockaddress() {
; CHECK-LABEL: test_blockaddress:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Ltmp7: ; Block address taken
; CHECK-NEXT:  ; %bb.1: ; %dest
; CHECK-NEXT:  Lloh24:
; CHECK-NEXT:    adrp x0, lCPI38_0@PAGE
; CHECK-NEXT:  Lloh25:
; CHECK-NEXT:    ldr x0, [x0, lCPI38_0@PAGEOFF]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpLdr Lloh24, Lloh25
  br label %dest
dest:
  ret ptr blockaddress(@test_blockaddress, %dest)
}

define ptr @test_indirectbr(ptr %dest) {
; CHECK-LABEL: test_indirectbr:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    br x0
; CHECK-NEXT:  Ltmp8: ; Block address taken
; CHECK-NEXT:  LBB39_1: ; %true
; CHECK-NEXT:  Lloh26:
; CHECK-NEXT:    adrp x0, lCPI39_0@PAGE
; CHECK-NEXT:  Lloh27:
; CHECK-NEXT:    ldr x0, [x0, lCPI39_0@PAGEOFF]
; CHECK-NEXT:    ret
; CHECK-NEXT:  Ltmp9: ; Block address taken
; CHECK-NEXT:  LBB39_2: ; %false
; CHECK-NEXT:  Lloh28:
; CHECK-NEXT:    adrp x0, lCPI39_1@PAGE
; CHECK-NEXT:  Lloh29:
; CHECK-NEXT:    ldr x0, [x0, lCPI39_1@PAGEOFF]
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpLdr Lloh26, Lloh27
; CHECK-NEXT:    .loh AdrpLdr Lloh28, Lloh29
  indirectbr ptr %dest, [label %true, label %false]

true:
  ret ptr blockaddress(@test_indirectbr, %true)
false:
  ret ptr blockaddress(@test_indirectbr, %false)
}

; ISelDAGToDAG tries to fold an offset FI load (in this case var+4) into the
; actual load instruction. This needs to be done slightly carefully since we
; claim the FI in the process -- it doesn't need extending.
define float @test_frameindex_offset_load() {
; CHECK-LABEL: test_frameindex_offset_load:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    sub sp, sp, #16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    ldr s0, [sp, #4]
; CHECK-NEXT:    add sp, sp, #16
; CHECK-NEXT:    ret
  %arr = alloca float, i32 4, align 8
  %addr = getelementptr inbounds float, ptr %arr, i32 1

  %val = load float, ptr %addr, align 4
  ret float %val
}

define void @test_unaligned_frameindex_offset_store() {
; CHECK-LABEL: test_unaligned_frameindex_offset_store:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    sub sp, sp, #16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    mov x8, sp
; CHECK-NEXT:    orr w8, w8, #0x2
; CHECK-NEXT:    mov w9, #42 ; =0x2a
; CHECK-NEXT:    str w9, [x8]
; CHECK-NEXT:    add sp, sp, #16
; CHECK-NEXT:    ret
  %arr = alloca [4 x i32]

  %addr.int = ptrtoint ptr %arr to i32
  %addr.nextint = add nuw i32 %addr.int, 2
  %addr.next = inttoptr i32 %addr.nextint to ptr
  store i32 42, ptr %addr.next
  ret void
}


define {i64, ptr} @test_pre_idx(ptr %addr) {
; CHECK-LABEL: test_pre_idx:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    add w1, w0, #8
; CHECK-NEXT:    ldr x0, [x1]
; CHECK-NEXT:    ret

  %addr.int = ptrtoint ptr %addr to i32
  %addr.next.int = add nuw i32 %addr.int, 8
  %addr.next = inttoptr i32 %addr.next.int to ptr
  %val = load i64, ptr %addr.next

  %tmp = insertvalue {i64, ptr} undef, i64 %val, 0
  %res = insertvalue {i64, ptr} %tmp, ptr %addr.next, 1

  ret {i64, ptr} %res
}

; Forming a post-indexed load is invalid here since the GEP needs to work when
; %addr wraps round to 0.
define {i64, ptr} @test_invalid_pre_idx(ptr %addr) {
; CHECK-LABEL: test_invalid_pre_idx:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    add w1, w0, #8
; CHECK-NEXT:    ldr x0, [x1]
; CHECK-NEXT:    ret
  %addr.next = getelementptr i64, ptr %addr, i32 1
  %val = load i64, ptr %addr.next

  %tmp = insertvalue {i64, ptr} undef, i64 %val, 0
  %res = insertvalue {i64, ptr} %tmp, ptr %addr.next, 1

  ret {i64, ptr} %res
}

declare void @callee(ptr)
define void @test_stack_guard() ssp {
; CHECK-OPT-LABEL: test_stack_guard:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:    sub sp, sp, #64
; CHECK-OPT-NEXT:    stp x29, x30, [sp, #48] ; 16-byte Folded Spill
; CHECK-OPT-NEXT:    add x29, sp, #48
; CHECK-OPT-NEXT:    .cfi_def_cfa w29, 16
; CHECK-OPT-NEXT:    .cfi_offset w30, -8
; CHECK-OPT-NEXT:    .cfi_offset w29, -16
; CHECK-OPT-NEXT:  Lloh30:
; CHECK-OPT-NEXT:    adrp x8, ___stack_chk_guard@GOTPAGE
; CHECK-OPT-NEXT:  Lloh31:
; CHECK-OPT-NEXT:    ldr w8, [x8, ___stack_chk_guard@GOTPAGEOFF]
; CHECK-OPT-NEXT:  Lloh32:
; CHECK-OPT-NEXT:    ldr w8, [x8]
; CHECK-OPT-NEXT:    stur w8, [x29, #-4]
; CHECK-OPT-NEXT:    add x0, sp, #12
; CHECK-OPT-NEXT:    bl _callee
; CHECK-OPT-NEXT:  Lloh33:
; CHECK-OPT-NEXT:    adrp x8, ___stack_chk_guard@GOTPAGE
; CHECK-OPT-NEXT:  Lloh34:
; CHECK-OPT-NEXT:    ldr w8, [x8, ___stack_chk_guard@GOTPAGEOFF]
; CHECK-OPT-NEXT:  Lloh35:
; CHECK-OPT-NEXT:    ldr w8, [x8]
; CHECK-OPT-NEXT:    ldur w9, [x29, #-4]
; CHECK-OPT-NEXT:    cmp w8, w9
; CHECK-OPT-NEXT:    b.ne LBB44_2
; CHECK-OPT-NEXT:  ; %bb.1:
; CHECK-OPT-NEXT:    ldp x29, x30, [sp, #48] ; 16-byte Folded Reload
; CHECK-OPT-NEXT:    add sp, sp, #64
; CHECK-OPT-NEXT:    ret
; CHECK-OPT-NEXT:  LBB44_2:
; CHECK-OPT-NEXT:    bl ___stack_chk_fail
; CHECK-OPT-NEXT:    .loh AdrpLdrGotLdr Lloh33, Lloh34, Lloh35
; CHECK-OPT-NEXT:    .loh AdrpLdrGotLdr Lloh30, Lloh31, Lloh32
;
; CHECK-FAST-LABEL: test_stack_guard:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:    sub sp, sp, #64
; CHECK-FAST-NEXT:    stp x29, x30, [sp, #48] ; 16-byte Folded Spill
; CHECK-FAST-NEXT:    add x29, sp, #48
; CHECK-FAST-NEXT:    .cfi_def_cfa w29, 16
; CHECK-FAST-NEXT:    .cfi_offset w30, -8
; CHECK-FAST-NEXT:    .cfi_offset w29, -16
; CHECK-FAST-NEXT:  Lloh30:
; CHECK-FAST-NEXT:    adrp x8, ___stack_chk_guard@GOTPAGE
; CHECK-FAST-NEXT:  Lloh31:
; CHECK-FAST-NEXT:    ldr w8, [x8, ___stack_chk_guard@GOTPAGEOFF]
; CHECK-FAST-NEXT:  Lloh32:
; CHECK-FAST-NEXT:    ldr w8, [x8]
; CHECK-FAST-NEXT:    stur w8, [x29, #-4]
; CHECK-FAST-NEXT:    add x0, sp, #12
; CHECK-FAST-NEXT:    bl _callee
; CHECK-FAST-NEXT:  Lloh33:
; CHECK-FAST-NEXT:    adrp x8, ___stack_chk_guard@GOTPAGE
; CHECK-FAST-NEXT:  Lloh34:
; CHECK-FAST-NEXT:    ldr w8, [x8, ___stack_chk_guard@GOTPAGEOFF]
; CHECK-FAST-NEXT:  Lloh35:
; CHECK-FAST-NEXT:    ldr w8, [x8]
; CHECK-FAST-NEXT:    ldur w9, [x29, #-4]
; CHECK-FAST-NEXT:    and x8, x8, #0xffffffff
; CHECK-FAST-NEXT:    cmp x8, x9
; CHECK-FAST-NEXT:    b.ne LBB44_2
; CHECK-FAST-NEXT:  ; %bb.1: ; %SP_return
; CHECK-FAST-NEXT:    ldp x29, x30, [sp, #48] ; 16-byte Folded Reload
; CHECK-FAST-NEXT:    add sp, sp, #64
; CHECK-FAST-NEXT:    ret
; CHECK-FAST-NEXT:  LBB44_2: ; %CallStackCheckFailBlk
; CHECK-FAST-NEXT:    bl ___stack_chk_fail
; CHECK-FAST-NEXT:    .loh AdrpLdrGotLdr Lloh33, Lloh34, Lloh35
; CHECK-FAST-NEXT:    .loh AdrpLdrGotLdr Lloh30, Lloh31, Lloh32



  %arr = alloca [8 x i32]
  call void @callee(ptr %arr)
  ret void
}

declare i32 @__gxx_personality_v0(...)
declare void @eat_landingpad_args(i32, ptr, i32)
@_ZTI8Whatever = external global i8
define void @test_landingpad_marshalling() personality ptr @__gxx_personality_v0 {
; CHECK-LABEL: test_landingpad_marshalling:
; CHECK:       Lfunc_begin0:
; CHECK-NEXT:    .cfi_startproc
; CHECK-NEXT:    .cfi_personality 155, ___gxx_personality_v0
; CHECK-NEXT:    .cfi_lsda 16, Lexception0
; CHECK-NEXT:  ; %bb.0:
; CHECK-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-NEXT:    mov x29, sp
; CHECK-NEXT:    .cfi_def_cfa w29, 16
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:  Ltmp3:
; CHECK-NEXT:    bl _callee
; CHECK-NEXT:  Ltmp4:
; CHECK-NEXT:  ; %bb.1: ; %done
; CHECK-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-NEXT:    ret
; CHECK-NEXT:  LBB45_2: ; %lpad
; CHECK-NEXT:  Ltmp5:
; CHECK-NEXT:    mov x2, x1
; CHECK-NEXT:    mov x1, x0
; CHECK-NEXT:    ; kill: def $w2 killed $w2 killed $x2
; CHECK-NEXT:    bl _eat_landingpad_args
; CHECK-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-NEXT:    ret
; CHECK-NEXT:  Lfunc_end0:
; CHECK-NEXT:    .cfi_endproc
; CHECK-NEXT:    .section __TEXT,__gcc_except_tab
; CHECK-NEXT:    .p2align 2, 0x0
; CHECK-NEXT:  GCC_except_table45:
; CHECK-NEXT:  Lexception0:
; CHECK-NEXT:    .byte 255 ; @LPStart Encoding = omit
; CHECK-NEXT:    .byte 155 ; @TType Encoding = indirect pcrel sdata4
; CHECK-NEXT:    .uleb128 Lttbase0-Lttbaseref0
; CHECK-NEXT:  Lttbaseref0:
; CHECK-NEXT:    .byte 1 ; Call site Encoding = uleb128
; CHECK-NEXT:    .uleb128 Lcst_end0-Lcst_begin0
; CHECK-NEXT:  Lcst_begin0:
; CHECK-NEXT:    .uleb128 Ltmp3-Lfunc_begin0 ; >> Call Site 1 <<
; CHECK-NEXT:    .uleb128 Ltmp4-Ltmp3 ; Call between Ltmp3 and Ltmp4
; CHECK-NEXT:    .uleb128 Ltmp5-Lfunc_begin0 ; jumps to Ltmp5
; CHECK-NEXT:    .byte 1 ; On action: 1
; CHECK-NEXT:    .uleb128 Ltmp4-Lfunc_begin0 ; >> Call Site 2 <<
; CHECK-NEXT:    .uleb128 Lfunc_end0-Ltmp4 ; Call between Ltmp4 and Lfunc_end0
; CHECK-NEXT:    .byte 0 ; has no landing pad
; CHECK-NEXT:    .byte 0 ; On action: cleanup
; CHECK-NEXT:  Lcst_end0:
; CHECK-NEXT:    .byte 1 ; >> Action Record 1 <<
; CHECK-NEXT:    ; Catch TypeInfo 1
; CHECK-NEXT:    .byte 0 ; No further actions
; CHECK-NEXT:    .p2align 2, 0x0
; CHECK-NEXT:    ; >> Catch TypeInfos <<
; CHECK-NEXT:  Ltmp10: ; TypeInfo 1
; CHECK-NEXT:    .long __ZTI8Whatever@GOT-Ltmp10
; CHECK-NEXT:  Lttbase0:
; CHECK-NEXT:    .p2align 2, 0x0
  invoke void @callee(ptr undef) to label %done unwind label %lpad

lpad:                                             ; preds = %entry
  %exc = landingpad { ptr, i32 }
          catch ptr @_ZTI8Whatever
  %pointer = extractvalue { ptr, i32 } %exc, 0
  %selector = extractvalue { ptr, i32 } %exc, 1
  call void @eat_landingpad_args(i32 undef, ptr %pointer, i32 %selector)
  ret void

done:
  ret void
}

define void @test_dynamic_stackalloc() {
; CHECK-LABEL: test_dynamic_stackalloc:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-NEXT:    mov x29, sp
; CHECK-NEXT:    .cfi_def_cfa w29, 16
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    sub x0, sp, #32
; CHECK-NEXT:    mov sp, x0
; CHECK-NEXT:    bl _callee
; CHECK-NEXT:    mov sp, x29
; CHECK-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-NEXT:    ret
  br label %next

next:
  %val = alloca [8 x i32]
  call void @callee(ptr %val)
  ret void
}

define void @test_asm_memory(ptr %base.addr) {
; CHECK-LABEL: test_asm_memory:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    add w8, w0, #4
; CHECK-NEXT:    ; InlineAsm Start
; CHECK-NEXT:    str wzr, [x8]
; CHECK-NEXT:    ; InlineAsm End
; CHECK-NEXT:    ret
  %addr = getelementptr i32, ptr %base.addr, i32 1
  call void asm sideeffect "str wzr, $0", "*m"(ptr elementtype(i32) %addr)
  ret void
}

define void @test_unsafe_asm_memory(i64 %val) {
; CHECK-LABEL: test_unsafe_asm_memory:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    and x8, x0, #0xffffffff
; CHECK-NEXT:    ; InlineAsm Start
; CHECK-NEXT:    str wzr, [x8]
; CHECK-NEXT:    ; InlineAsm End
; CHECK-NEXT:    ret
  %addr_int = trunc i64 %val to i32
  %addr = inttoptr i32 %addr_int to ptr
  call void asm sideeffect "str wzr, $0", "*m"(ptr elementtype(i32) %addr)
  ret void
}

define [9 x ptr] @test_demoted_return(ptr %in) {
; CHECK-LABEL: test_demoted_return:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    str w0, [x8, #32]
; CHECK-NEXT:    ret
  %res = insertvalue [9 x ptr] undef, ptr %in, 8
  ret [9 x ptr] %res
}

define ptr @test_inttoptr(i64 %in) {
; CHECK-LABEL: test_inttoptr:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    and x0, x0, #0xffffffff
; CHECK-NEXT:    ret
  %res = inttoptr i64 %in to ptr
  ret ptr %res
}

declare i32 @llvm.get.dynamic.area.offset.i32()
define i32 @test_dynamic_area() {
; CHECK-LABEL: test_dynamic_area:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    mov w0, wzr
; CHECK-NEXT:    ret
  %res = call i32 @llvm.get.dynamic.area.offset.i32()
  ret i32 %res
}

define void @test_pointer_vec_store(ptr %addr) {
; CHECK-LABEL: test_pointer_vec_store:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    str xzr, [x0]
; CHECK-NEXT:    ret

  store <2 x ptr> zeroinitializer, ptr %addr, align 16
  ret void
}

define <2 x ptr> @test_pointer_vec_load(ptr %addr) {
; CHECK-LABEL: test_pointer_vec_load:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    ldr d0, [x0]
; CHECK-NEXT:    ushll.2d v0, v0, #0
; CHECK-NEXT:    ret
  %val = load <2 x ptr>, ptr %addr, align 16
  ret <2 x ptr> %val
}

define void @test_inline_asm_mem_pointer(ptr %in) {
; CHECK-LABEL: test_inline_asm_mem_pointer:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    sub sp, sp, #16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    add x8, sp, #12
; CHECK-NEXT:    str w0, [sp, #12]
; CHECK-NEXT:    ; InlineAsm Start
; CHECK-NEXT:    ldr x0, [x8]
; CHECK-NEXT:    ; InlineAsm End
; CHECK-NEXT:    add sp, sp, #16
; CHECK-NEXT:    ret
  tail call void asm sideeffect "ldr x0, $0", "m"(ptr %in)
  ret void
}


define void @test_struct_hi(i32 %hi) nounwind {
; CHECK-OPT-LABEL: test_struct_hi:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:    stp x20, x19, [sp, #-32]! ; 16-byte Folded Spill
; CHECK-OPT-NEXT:    stp x29, x30, [sp, #16] ; 16-byte Folded Spill
; CHECK-OPT-NEXT:    add x29, sp, #16
; CHECK-OPT-NEXT:    mov w19, w0
; CHECK-OPT-NEXT:    bl _get_int
; CHECK-OPT-NEXT:    bfi x0, x19, #32, #32
; CHECK-OPT-NEXT:    bl _take_pair
; CHECK-OPT-NEXT:    ldp x29, x30, [sp, #16] ; 16-byte Folded Reload
; CHECK-OPT-NEXT:    ldp x20, x19, [sp], #32 ; 16-byte Folded Reload
; CHECK-OPT-NEXT:    ret
;
; CHECK-FAST-LABEL: test_struct_hi:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:    stp x20, x19, [sp, #-32]! ; 16-byte Folded Spill
; CHECK-FAST-NEXT:    stp x29, x30, [sp, #16] ; 16-byte Folded Spill
; CHECK-FAST-NEXT:    add x29, sp, #16
; CHECK-FAST-NEXT:    mov w19, w0
; CHECK-FAST-NEXT:    bl _get_int
; CHECK-FAST-NEXT:    mov w8, w0
; CHECK-FAST-NEXT:    orr x0, x8, x19, lsl #32
; CHECK-FAST-NEXT:    bl _take_pair
; CHECK-FAST-NEXT:    ldp x29, x30, [sp, #16] ; 16-byte Folded Reload
; CHECK-FAST-NEXT:    ldp x20, x19, [sp], #32 ; 16-byte Folded Reload
; CHECK-FAST-NEXT:    ret
  %val.64 = call i64 @get_int()
  %val.32 = trunc i64 %val.64 to i32

  %pair.0 = insertvalue [2 x i32] undef, i32 %val.32, 0
  %pair.1 = insertvalue [2 x i32] %pair.0, i32 %hi, 1
  call void @take_pair([2 x i32] %pair.1)

  ret void
}
declare void @take_pair([2 x i32])
declare i64 @get_int()

define i1 @test_icmp_ptr(ptr %in) {
; CHECK-LABEL: test_icmp_ptr:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    ubfx x0, x0, #31, #1
; CHECK-NEXT:    ; kill: def $w0 killed $w0 killed $x0
; CHECK-NEXT:    ret
  %res = icmp slt ptr %in, null
  ret i1 %res
}

define void @test_multiple_icmp_ptr(ptr %l, ptr %r) {
; CHECK-OPT-LABEL: test_multiple_icmp_ptr:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:    tbnz w0, #31, LBB57_3
; CHECK-OPT-NEXT:  ; %bb.1:
; CHECK-OPT-NEXT:    tbnz w1, #31, LBB57_3
; CHECK-OPT-NEXT:  ; %bb.2: ; %true
; CHECK-OPT-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-OPT-NEXT:    mov x29, sp
; CHECK-OPT-NEXT:    .cfi_def_cfa w29, 16
; CHECK-OPT-NEXT:    .cfi_offset w30, -8
; CHECK-OPT-NEXT:    .cfi_offset w29, -16
; CHECK-OPT-NEXT:    bl _bar
; CHECK-OPT-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-OPT-NEXT:  LBB57_3: ; %false
; CHECK-OPT-NEXT:    ret
;
; CHECK-FAST-LABEL: test_multiple_icmp_ptr:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:    tbnz w0, #31, LBB57_3
; CHECK-FAST-NEXT:  ; %bb.1: ; %.cond.split
; CHECK-FAST-NEXT:    tbnz w1, #31, LBB57_3
; CHECK-FAST-NEXT:  ; %bb.2: ; %true
; CHECK-FAST-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-FAST-NEXT:    mov x29, sp
; CHECK-FAST-NEXT:    .cfi_def_cfa w29, 16
; CHECK-FAST-NEXT:    .cfi_offset w30, -8
; CHECK-FAST-NEXT:    .cfi_offset w29, -16
; CHECK-FAST-NEXT:    bl _bar
; CHECK-FAST-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-FAST-NEXT:  LBB57_3: ; %false
; CHECK-FAST-NEXT:    ret
  %tst1 = icmp sgt ptr %l, inttoptr (i32 -1 to ptr)
  %tst2 = icmp sgt ptr %r, inttoptr (i32 -1 to ptr)
  %tst = and i1 %tst1, %tst2
  br i1 %tst, label %true, label %false

true:
  call void(...) @bar()
  ret void

false:
  ret void
}

define void @test_multiple_icmp_ptr_select(ptr %l, ptr %r) {
; CHECK-OPT-LABEL: test_multiple_icmp_ptr_select:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:    tbnz w0, #31, LBB58_3
; CHECK-OPT-NEXT:  ; %bb.1:
; CHECK-OPT-NEXT:    tbnz w1, #31, LBB58_3
; CHECK-OPT-NEXT:  ; %bb.2: ; %true
; CHECK-OPT-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-OPT-NEXT:    mov x29, sp
; CHECK-OPT-NEXT:    .cfi_def_cfa w29, 16
; CHECK-OPT-NEXT:    .cfi_offset w30, -8
; CHECK-OPT-NEXT:    .cfi_offset w29, -16
; CHECK-OPT-NEXT:    bl _bar
; CHECK-OPT-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-OPT-NEXT:  LBB58_3: ; %false
; CHECK-OPT-NEXT:    ret
;
; CHECK-FAST-LABEL: test_multiple_icmp_ptr_select:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:    tbnz w0, #31, LBB58_3
; CHECK-FAST-NEXT:  ; %bb.1: ; %.cond.split
; CHECK-FAST-NEXT:    tbnz w1, #31, LBB58_3
; CHECK-FAST-NEXT:  ; %bb.2: ; %true
; CHECK-FAST-NEXT:    stp x29, x30, [sp, #-16]! ; 16-byte Folded Spill
; CHECK-FAST-NEXT:    mov x29, sp
; CHECK-FAST-NEXT:    .cfi_def_cfa w29, 16
; CHECK-FAST-NEXT:    .cfi_offset w30, -8
; CHECK-FAST-NEXT:    .cfi_offset w29, -16
; CHECK-FAST-NEXT:    bl _bar
; CHECK-FAST-NEXT:    ldp x29, x30, [sp], #16 ; 16-byte Folded Reload
; CHECK-FAST-NEXT:  LBB58_3: ; %false
; CHECK-FAST-NEXT:    ret
  %tst1 = icmp sgt ptr %l, inttoptr (i32 -1 to ptr)
  %tst2 = icmp sgt ptr %r, inttoptr (i32 -1 to ptr)
  %tst = select i1 %tst1, i1 %tst2, i1 false
  br i1 %tst, label %true, label %false

true:
  call void(...) @bar()
  ret void

false:
  ret void
}

define ptr @test_gep_nonpow2(ptr %a0, i32 %a1) {
; CHECK-OPT-LABEL: test_gep_nonpow2:
; CHECK-OPT:       ; %bb.0:
; CHECK-OPT-NEXT:    mov w8, #18 ; =0x12
; CHECK-OPT-NEXT:    smaddl x0, w1, w8, x0
; CHECK-OPT-NEXT:    ret
;
; CHECK-FAST-LABEL: test_gep_nonpow2:
; CHECK-FAST:       ; %bb.0:
; CHECK-FAST-NEXT:    mov w8, #18 ; =0x12
; CHECK-FAST-NEXT:    smaddl x8, w1, w8, x0
; CHECK-FAST-NEXT:    and x0, x8, #0xffffffff
; CHECK-FAST-NEXT:    ret

  %tmp0 = getelementptr inbounds { [18 x i8] }, ptr %a0, i32 %a1
  ret ptr %tmp0
}

define void @test_memset(i64 %in, i8 %value)  {
; CHECK-LABEL: test_memset:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    lsr x2, x0, #32
; CHECK-NEXT:    and x0, x0, #0xffffffff
; CHECK-NEXT:    ; kill: def $w2 killed $w2 killed $x2
; CHECK-NEXT:    b _memset

  %ptr.i32 = trunc i64 %in to i32
  %size.64 = lshr i64 %in, 32
  %size = trunc i64 %size.64 to i32
  %ptr = inttoptr i32 %ptr.i32 to ptr
  tail call void @llvm.memset.p0.i32(ptr align 4 %ptr, i8 %value, i32 %size, i1 false)
  ret void
}

define void @test_bzero(i64 %in)  {
; CHECK-LABEL: test_bzero:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    lsr x1, x0, #32
; CHECK-NEXT:    and x0, x0, #0xffffffff
; CHECK-NEXT:    ; kill: def $w1 killed $w1 killed $x1
; CHECK-NEXT:    b _bzero

  %ptr.i32 = trunc i64 %in to i32
  %size.64 = lshr i64 %in, 32
  %size = trunc i64 %size.64 to i32
  %ptr = inttoptr i32 %ptr.i32 to ptr
  tail call void @llvm.memset.p0.i32(ptr align 4 %ptr, i8 0, i32 %size, i1 false)
  ret void
}

declare void @llvm.memset.p0.i32(ptr nocapture writeonly, i8, i32, i1)

define i1 @test_stackguard(ptr %p1) {
; CHECK-LABEL: test_stackguard:
; CHECK:       ; %bb.0:
; CHECK-NEXT:  Lloh36:
; CHECK-NEXT:    adrp x8, ___stack_chk_guard@GOTPAGE
; CHECK-NEXT:  Lloh37:
; CHECK-NEXT:    ldr w8, [x8, ___stack_chk_guard@GOTPAGEOFF]
; CHECK-NEXT:  Lloh38:
; CHECK-NEXT:    ldr w8, [x8]
; CHECK-NEXT:    cmp w8, w0
; CHECK-NEXT:    cset w0, ne
; CHECK-NEXT:    ret
; CHECK-NEXT:    .loh AdrpLdrGotLdr Lloh36, Lloh37, Lloh38

  %p2 = call ptr @llvm.stackguard()
  %res = icmp ne ptr %p2, %p1
  ret i1 %res
}
declare ptr @llvm.stackguard()
@__stack_chk_guard = external global i32


!llvm.module.flags = !{!0}
!0 = !{i32 7, !"PIC Level", i32 2}
